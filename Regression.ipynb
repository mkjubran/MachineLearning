{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LinearRegression.ipynb",
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkjubran/MachineLearning/blob/master/Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzmEcNHzuBI3",
        "colab_type": "text"
      },
      "source": [
        "# Clone the Source GitHub Reporsitory \n",
        "We need to clone some source files to be used throughtout this tutorial from a GitHub reprository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmP4GrRNudXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf ./MachineLearning\n",
        "!git clone https://github.com/mkjubran/MachineLearning.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIlzJbCpmo0R",
        "colab_type": "text"
      },
      "source": [
        "# Linear Regression\n",
        "**Introduction**\n",
        "\n",
        "In this section, we will come up with a technique to estimate the prices of houses based on their area (size). This is achieved through the following procedure: \\\\\n",
        "1- collect some statistics about houses which include the area and price of each house, \\\\\n",
        "2- we will use this data to build a model to correlate the prices of the houses with their area, \\\\\n",
        "3- next, we will use the model to estimate the prices of new houses based on their areas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeQ0wuIc1AHR",
        "colab_type": "text"
      },
      "source": [
        "**Theory** \\\\\n",
        "\n",
        "Linear regression is a linear approach to modeling the relationship between a scalar response (or dependent variable) and one or more explanatory variables (or independent variables). $^{[1]}$ \\\\\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1_r9xTDOQbhv42ystuiIzFryatHAwuuyg)\n",
        "\n",
        "But we might have different options to represent this relation as shown in the figure below:\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1HvCkHLnCVWP5MHM-YWR_0kqqbvfflSnY)\n",
        "\n",
        "We need to determine the values of **m** and **b** which minimize the residual error between actual and predicted values of the dependent variable (y).\\\\\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=10nLdNVaRfmi5_-tq8LzST39JnrPltzZC)\n",
        "\n",
        "\n",
        "\n",
        "[1] https://en.wikipedia.org/wiki/Linear_regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RSwASngm9_9",
        "colab_type": "text"
      },
      "source": [
        "**Implementation**\n",
        "\n",
        "In a previous module, you learned how to extract and collect data. Now, let us assume the data which includes areas and prices of houses are saved in a csv file called \"HouseAreasPrices.csv\" \\\\\n",
        "To read the data in the file, we will be using the pandas library (https://pandas.pydata.org/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQX2iq_fnJOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"./MachineLearning/1_Regression/HousesAreasPrices.csv\")\n",
        "print(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJA9kY1o6_lr",
        "colab_type": "text"
      },
      "source": [
        "Now, to visualize the data, we will plot the pairs (area, price) of each house on a scattered plot. To do this we need to use the matplotlib library (https://matplotlib.org/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ABqNIrJ7fLr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(df.area,df.price,color='r', marker='+')\n",
        "plt.xlabel('Area ($m^2$)',fontsize=20)\n",
        "plt.ylabel('Prices ($)',fontsize=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yZaiJXQ8NFv",
        "colab_type": "text"
      },
      "source": [
        "As can be observed from the plot, a straight line can be used to represent the data. So we will use the LinearRegression method in the sklearn library (https://scikit-learn.org/stable/) to derive the best fitting line (determine the best coefficient and interception values) based on the given data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lh4GU2-ROob8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import linear_model\n",
        "reg = linear_model.LinearRegression()\n",
        "reg.fit(df[['area']],df.price)\n",
        "print(reg.coef_) ## print the coefficient\n",
        "print(reg.intercept_) ## print the intercept"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axZLROWNOzaj",
        "colab_type": "text"
      },
      "source": [
        "To visualize the line, we plot the best fitting line on the scattered plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2UwirZYPHg5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.scatter(df.area,df.price,color='r', marker='+')\n",
        "plt.xlabel('Area ($m^2$)',fontsize=20)\n",
        "plt.ylabel('Prices ($)',fontsize=20)\n",
        "plt.plot(df.area,reg.predict(df[['area']]),color='b')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CbQPKN8QKF6",
        "colab_type": "text"
      },
      "source": [
        "After building the model, we will use it to estimate the prices of a list of houses based on their areas. Let us assume that the areas of few houses are stored in a csv file called \"HousesAreas.csv\". We will read the data from the file into a dataframe, and apply the area values in the dataframe to the model to determine the estimated prices, then we will append the estimated prices to the dataframe and store the new dataframe to a new csv file called \"PredictedHouusesAreasPrices.csv\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0T7_4oYmmDo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2 = pd.read_csv(\"./MachineLearning/1_Regression/HousesAreas.csv\")\n",
        "p=reg.predict(df2)\n",
        "df2['price']=p\n",
        "print(df2)\n",
        "df2.to_csv('./MachineLearning/1_Regression/PredictHousesAreasPrices.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6hurFfaRXCm",
        "colab_type": "text"
      },
      "source": [
        "We could also plot the estimated prices with the original data and the best fitting line on the same figure as"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tP9gj5LqYilr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_merged= df.append(df2, ignore_index=True)\n",
        "\n",
        "plt.scatter(df.area,df.price,color='r', marker='+')\n",
        "plt.xlabel('Area ($m^2$)',fontsize=20)\n",
        "plt.ylabel('Prices ($)',fontsize=20)\n",
        "plt.plot(df_merged.area, reg.predict(df_merged[['area']]),color='b',linestyle='-.',linewidth=0.5)\n",
        "plt.scatter(df2.area,df2.price,color='m', marker='o')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FR-SYXGGlBwr",
        "colab_type": "text"
      },
      "source": [
        "As can be observed from the figure, the estimated prices of the new houses are located on the best fit line"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rFQOBBCtqlE",
        "colab_type": "text"
      },
      "source": [
        "**Exercise**\n",
        "\n",
        "Use linear regression to estimate the prices of the houses based on how old the houses are. To complete this exercise, two files are included in the repository: \\\\\n",
        "1- HousesAgesPrices.csv: a list of houses' prices and their ages \\\\\n",
        "2- HousesAges.csv: a list of ages of houses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f-VPoRayLM7",
        "colab_type": "text"
      },
      "source": [
        "# Multiple Regression\n",
        "**Introduction**\n",
        "\n",
        "In this section, we will extend the model derives in the Linear Regression section to include more than one independent variable. This method is called Multiple Regression. We will use multiple properties of the house (area, number of rooms, age) to predict its price."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWhZGsyYNEPV",
        "colab_type": "text"
      },
      "source": [
        "**Theory**\n",
        "\n",
        "Multiple regression is an extension of simple linear regression. It is used when we want to predict the value of a variable based on the value of two or more other variables. The variable we want to predict is called the dependent variable (or sometimes, the outcome, target or criterion variable). The variables we are using to predict the value of the dependent variable are called the independent variables (or sometimes, the predictor, explanatory or regressor variables). For example, you could use multiple regression to understand whether exam performance can be predicted based on revision time, test anxiety, lecture attendance and gender. $^{[2]}$\n",
        "\n",
        "[2] https://statistics.laerd.com/spss-tutorials/multiple-regression-using-spss-statistics.php"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsWik1emdqRJ",
        "colab_type": "text"
      },
      "source": [
        "**Implementation**\n",
        "\n",
        "Read the data in the file \"HousesPrices.csv\" using pandas libarary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL4EcjFsdp0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"./MachineLearning/1_Regression/HousesPrices.csv\")\n",
        "print(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAsnCGlEhh0_",
        "colab_type": "text"
      },
      "source": [
        "In the above table, there is more than one feature that corresponds to the price of each house. In the multivariate, the number of input independent variables (features) is at least two or more. In our case, the features are area, number of bedrooms, and age of the house. And the dependent variable is the price of the house. \n",
        "\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1a4tq7w_mewJ3gUykvvT5PiOg4rXKsBMJ)\n",
        "\n",
        "\n",
        "We notice that there is a NaN number of bedrooms next to house index 2, this is typically due to empty value in the csv file. Thus, we need to process the dataframe to clean the data. In our case, we will replace the NaN value with the median of the other bedroom values in the table."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p415q6o7ma7y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "median_bedrooms = df.bedrooms.median() # media of number of bedrooms in dataframe\n",
        "print(median_bedrooms)\n",
        "median_bedrooms = math.floor(df.bedrooms.median())# use the math library to compute the floor of the media of number of bedrooms in dataframe\n",
        "print(median_bedrooms)\n",
        "df.bedrooms = df.bedrooms.fillna(median_bedrooms) #replace the NAN with the median value\n",
        "print(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1Fmyz__mPvw",
        "colab_type": "text"
      },
      "source": [
        "Now the data is clean. Next, we will use the LinearRegression method in the sklearn library (https://scikit-learn.org/stable/) to derive the best fitting line (determine the best coefficients and interception values) based on the given data. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEIeK_ZChge4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import linear_model\n",
        "regm = linear_model.LinearRegression()\n",
        "regm.fit(df[['area','bedrooms','age']],df.price)\n",
        "print(regm.coef_) ## print the coefficients\n",
        "print(regm.intercept_) ## print the intercept"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siDScZ1Q4nFs",
        "colab_type": "text"
      },
      "source": [
        "After building the model, we will use it to estimate the prices of a list of houses based on their features (area, number of bedrooms, age). Let us assume features of few houses are stored in a csv file called \"HousesFeatures.csv\". We will read the data from the file into a dataframe, and apply the values of the features in the dataframe to the model to determine the estimated prices, then we will append the etimted prices to the dataframe and store the new dataframe to new csv file called \"PredictedHouusesFeaturesPrices.csv\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA5CQ5Qy6TVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfm = pd.read_csv(\"./MachineLearning/1_Regression/HousesFeatures.csv\")\n",
        "p=regm.predict(dfm)\n",
        "dfm['price']=p\n",
        "print(dfm)\n",
        "dfm.to_csv('./MachineLearning/1_Regression/PredictHousesFeaturesPrices.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_uYKRTART1F",
        "colab_type": "text"
      },
      "source": [
        "Optional: we could also check the residul error between the actual prices (in 'HousesPrices.csv') and the predicted values. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ry8163yR5PS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ppr=regm.predict(df[['area','bedrooms','age']])\n",
        "df['predicted_prices']=ppr\n",
        "df['Residual']=df['price']-df['predicted_prices']\n",
        "print(df)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAX3BodQ7OcN",
        "colab_type": "text"
      },
      "source": [
        "**Exercise (1)**\n",
        "Use multiple regression to estimate the prices of the houses based on houses' features. To complete this exercise, two files are included in the repository: \\\\\n",
        "1- HousesPrices_Exercise.csv: a list of houses' prices and their features \\\\\n",
        "2- HousesFeatures_Exercise.csv: a list of ages of houses\n",
        "\n",
        "hint: use the word2number (https://pypi.org/project/word2number/) library to convert number words (eg. twenty one) to numeric digits (21).\n",
        "\n",
        "**Exercise (2)**\n",
        "Use multiple regression to estimate the salary of a person based on experience, test results, and interview score. You are given some data in the \"hiring.csv\" file included in the repository. You need to propose a salary for the following two persons: \n",
        "\n",
        "**Person 1**: nine years of experience, 9 in the test score, and 6 in the interview, \\\\\n",
        "**Person 2**: twelve years of experience, 10 in the test score, and 9 in the interview "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hekbanaGUK6M",
        "colab_type": "text"
      },
      "source": [
        "# Cost Function and Gradient Descent\n",
        "In this section, we will learn how to use gradient descent to determine the optimal coefficients and intercept of linear regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjbP4FeiUqRZ",
        "colab_type": "text"
      },
      "source": [
        "**Theory**\n",
        "\n",
        "In Machine Learning (ML), cost function is a measure of how wrong the model is in terms of its ability to estimate the relationship between the independent variable (x) and the dependent variable (y). This is typically expressed as a difference or distance between the predicted value and the actual value.$^{[1]}$ One common cost function that is often used and will be used in this sesisons is mean squared error (MSE), which measures the difference between the ground truth ($y_i$) and the estimated value ($\\hat{y}_i$). \\\\\n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{aligned}\n",
        "MSE=\\frac{1}{n} \\sum^n_{i=1}{(y_i -\\hat{y}_i)^2}   \n",
        "\\end{aligned}\n",
        "\\end{equation}\n",
        "\n",
        "The cost function (you may also see this referred to as loss or error.) can be estimated by iteratively running the model to compare estimated predictions against “ground truth” — the known values of y. The objective of a ML model, therefore, is to find parameters, weights or a structure that minimises the cost function.$^{[1]}$ Gradient descent is an efficient optimization algorithm that attempts to find a local or global minima of a function. **Gradient descent** enables a model to learn the gradient or direction that the model should take in order to reduce errors (differences between actual y and predicted y).$^{[1]}$\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1fRW5deq8-LDrJcA537TvCOpDvChSk1pa)\n",
        "\n",
        "In the linear regression case, we need to determine the values of **m** and **b** that minimize the cost function (**MSE**) as shown below. \n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1-djT6TUolxA_C5eDiX0hIAZcD7M68vCn)\n",
        "\n",
        "We will use the gradient descent to determine the direction and step size to progress from an initial point toward the global minimum of the **MSE**. \n",
        "![alt text](https://drive.google.com/uc?id=16MCwuGihzmVaRYziuy5jxvWnE5m1sr_3)\n",
        "\n",
        "Given a set of data point, below is a visualization of how the gradient descent works $^{2}$\n",
        "\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=11MmCe-tEwK_SQ-qwwbc4ZY2QpE8GhIL4)\n",
        "\n",
        "\n",
        "[1] https://towardsdatascience.com/machine-learning-fundamentals-via-linear-regression-41a5d11f5220\n",
        "\n",
        "[2] https://github.com/mattnedrich/GradientDescentExample/blob/master/gradient_descent_example.gif\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fb8rhJC7W1Ap",
        "colab_type": "text"
      },
      "source": [
        "**Readings and Resources** \\\\\n",
        "1- https://towardsdatascience.com/machine-learning-fundamentals-via-linear-regression-41a5d11f5220\n",
        "\n",
        "2- https://medium.com/@lachlanmiller_52885/machine-learning-week-1-cost-function-gradient-descent-and-univariate-linear-regression-8f5fe69815fd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2fMSaUmUbDP",
        "colab_type": "text"
      },
      "source": [
        "**Implementation**\n",
        "\n",
        "In order to determine the best fit line, we need to determine the values of **m** and **b** of the straight line $\\hat{y}_i=mx_i+b$ that minimze the MSE. \n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{aligned}\n",
        "MSE=J=\\frac{1}{n} \\sum^n_{i=1}{(y_i -\\hat{y}_i)^2}   \n",
        "\\end{aligned}\n",
        "\\end{equation}\n",
        "\n",
        "So we substitute $\\hat{y}_i=mx_i+b$ into the cost function as\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{aligned}\n",
        "J=\\frac{1}{n} \\sum^n_{i=1}{(y_i -mx_i+b)^2}   \n",
        "\\end{aligned}\n",
        "\\end{equation}\n",
        "\n",
        "Then, we determine the gradient by taking the partial derivative of the cost function with respect to **m** and **b** as\n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{aligned}\n",
        "\\frac{\\partial J}{\\partial m}=\\frac{2}{n} \\sum^n_{i=1}{(y_i -mx_i+b) \\times (-x_i)} \n",
        "\\end{aligned}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{aligned}\n",
        "\\frac{\\partial J}{\\partial b}=\\frac{2}{n} \\sum^n_{i=1}{(y_i -mx_i+b) \\times (-1)} \n",
        "\\end{aligned}\n",
        "\\end{equation}\n",
        "\n",
        "So now to implement the gradient descent, we start with some values of **m** ($m_0$) and **b** ($b_0$) and iteratively modify them according the gradient and learning rate ($\\lambda$) as follows:\n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{aligned}\n",
        "m_i = m_{i-1} - \\lambda \\times \\frac{\\partial J}{\\partial m} \n",
        "\\end{aligned}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{aligned}\n",
        "b_i = b_{i-1} - \\lambda \\times \\frac{\\partial J}{\\partial b} \n",
        "\\end{aligned}\n",
        "\\end{equation}\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MK89QcjYqdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def gradient_descent_basic(x,y,m_curr,b_curr,learning_rate,iterations):\n",
        "    n = len(x)\n",
        "    for i in range(iterations):\n",
        "        y_pred = m_curr * x + b_curr\n",
        "        \n",
        "        md = - ( 2 / n ) * sum( x * ( y - y_pred ))\n",
        "        bd = - ( 2 / n ) * sum(( y - y_pred ))\n",
        "\n",
        "        m_curr = m_curr - learning_rate * md \n",
        "        b_curr = b_curr - learning_rate * bd \n",
        "\n",
        "        J = ( 1 / n ) * sum(( y - y_pred )**2)\n",
        "\n",
        "        print('J = {}, m = {}, b = {}, Iteration = {}'.format(J ,m_curr, b_curr, i ))\n",
        "    return m_curr,b_curr,i,J\n",
        "\n",
        "## try the gradient_descent using sample data\n",
        "x = np.array([0,1,2,3]);\n",
        "y = np.array([1,3,5,7]); ## y=2x+1\n",
        "\n",
        "m_curr = 0; b_curr = 0;\n",
        "gradient_descent_basic(x,y,m_curr,b_curr,0.2,20) ## learning rate = 0.2 and iteration = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcFNmc4zeRtR",
        "colab_type": "text"
      },
      "source": [
        "Let us increase learning rate to 0.5 and see how the gradient descent converges."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pms6CmU-ei8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## try the gradient_descent with learning rate = 0.5 and iteration = 20\n",
        "m_curr = 0; b_curr = 0;\n",
        "gradient_descent_basic(x,y,m_curr,b_curr,0.5,20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gOaimdMetgm",
        "colab_type": "text"
      },
      "source": [
        "As can be seen, the cost function increases instead of descreasing.\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1Urf6nAJ0-G5miH1EdCk4gCo5ctBtqVTh)\n",
        "\n",
        "So usually, we start with low iteration value and some value of learning rate and see if the cost function is reducing.  Then we increase the learning rate slowly to the value just before the cost function starts increasing. This value is the best learning rate (converge with the least number of iterations).\n",
        "\n",
        "Regarding the required number of iterations, you may stop the gradient descent search once the difference in the cost function between successive iterations reduces to less than some value (such as 1e-5 or 1e-6). Next we will modify the code to stop when the error (MSE) is less than 1e-6."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo6-diDXwB9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import copy\n",
        "def gradient_descent(x,y,m_curr,b_curr,learning_rate,epochs):\n",
        "    n = len(x)\n",
        "    i = 0 \n",
        "    j_curr = 100000\n",
        "    while True:\n",
        "        i= i + 1\n",
        "        j_before = j_curr\n",
        "        y_pred = m_curr * x + b_curr\n",
        "        \n",
        "        md = - ( 2 / n ) * sum( x * ( y - y_pred ))\n",
        "        bd = - ( 2 / n ) * sum( y - y_pred )\n",
        "\n",
        "        m_curr = m_curr - learning_rate * md \n",
        "        b_curr = b_curr - learning_rate * bd \n",
        "\n",
        "        j_curr = ( 1 / n ) * sum(( y - y_pred )**2)\n",
        "\n",
        "        if ((abs(j_curr - j_before) < 1e-5) or (i >= epochs)):\n",
        "          return m_curr,b_curr,i,j_curr\n",
        "\n",
        "## try the gradient_descent using sample data\n",
        "x = np.array([0,1,2,3]);\n",
        "y = np.array([1,3,5,7]); ## y=2x+1\n",
        "\n",
        "m_curr = 0; b_curr = 0;\n",
        "gradient_descent(x,y,m_curr,b_curr,0.2,100) ## learning rate = 0.2 and iteration = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQJ2qOQhpA97",
        "colab_type": "text"
      },
      "source": [
        "Next, we will solve the original problem (linear regression section) using our gradient descent implementation: \\\\\n",
        "1- Read the data in the file \"HousesAreasPrices.csv\" using pandas libarary, \\\\\n",
        "2- convert the fields in the data frame to np.arrays, \\\\\n",
        "3- then we apply the gradient_descent(x,y) on the np.arrays. \\\\\n",
        "Recall, the solution we got in the linear regression section is **m** = 135.78767123 and **b** = 180616.43835616432"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tdO_CtTnHhm",
        "colab_type": "text"
      },
      "source": [
        "Let us begin by determining the learning rate. We will use gradient_descent_basic() to print error while trying different learning rate values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3NI9Y7RmhzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"./MachineLearning/1_Regression/HousesAreasPrices.csv\")\n",
        "print(df)\n",
        "x=np.array(df.area)\n",
        "y=np.array(df.price)\n",
        "## change the learning rate and iterations\n",
        "m_gd, b_gd, iters, j_curr= gradient_descent_basic(x,y,0,0,0.00000001,20)\n",
        "print('J= {}, m = {}, b = {}, iterations = {}'.format(j_curr, m_gd, b_gd,iters))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqN0-ca6n0cq",
        "colab_type": "text"
      },
      "source": [
        "As can be observed, we need to use very low learning rate to make sure error is decreasing. However, such a low learning rate needs a lot of iterations to converge. To deal with this we apply data scaling. So we scale the independent random variable according to its mean and standard deviations. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtQvQovRoZo1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"./MachineLearning/1_Regression/HousesAreasPrices.csv\")\n",
        "print(df)\n",
        "x=np.array(df.area)\n",
        "y=np.array(df.price)\n",
        "\n",
        "## scaling the independent random variable\n",
        "x_new = (x - np.mean(x)) / np.std(x)\n",
        "\n",
        "## change the learning rate and iterations\n",
        "m_gd, b_gd, iters, j_curr= gradient_descent_basic(x_new,y,0,0,0.1,20)\n",
        "print('J = {}, m = {}, b = {}, iterations = {}'.format(j_curr, m_gd, b_gd,iters))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp7Ih9WmqrF7",
        "colab_type": "text"
      },
      "source": [
        "Now, to find the best coefficients, we increase the number of iterations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YTt_fwzqzIQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## change the learning rate and iterations\n",
        "m_gd, b_gd, iters, j_curr= gradient_descent(x_new,y,0,0,0.01,20000)\n",
        "print('J = {}, m = {}, b = {}, iterations = {}'.format(j_curr, m_gd, b_gd,iters))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RirEHpNwuc3H",
        "colab_type": "text"
      },
      "source": [
        "Notice that the number of iterations required such that the difference between MSE of successive iterations is less than 1e-5 is 868 only."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-3pKQAYtzNd",
        "colab_type": "text"
      },
      "source": [
        "As an inclass exercise, we will compare the error function between the rg.fit method (linear regression section) and the gradient descent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-bQ-1xg8dd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m_reg = 135.78767123; ## from linear regression section\n",
        "b_reg = 180616.43835616432; ## from linear regression section\n",
        "\n",
        "m_gd ## from gradient descient results in code cell above\n",
        "b_gd ## from gradient descient results in code cell above\n",
        "\n",
        "y_actual = np.array(df.price)\n",
        "y_pred_reg = m_reg * x + b_reg;\n",
        "y_pred_gd = m_gd * x_new + b_gd;\n",
        "\n",
        "n=len(y_actual)\n",
        "\n",
        "J_reg = (1/n)*sum(abs(y_actual - y_pred_reg));\n",
        "J_gd = (1/n)*sum(abs(y_actual - y_pred_gd));\n",
        "\n",
        "dif = J_reg - J_gd;\n",
        "\n",
        "print('J_reg = {}, J_gd = {}, Difference = {}'.format(J_reg, J_gd, dif))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3JbTFOTDVZn",
        "colab_type": "text"
      },
      "source": [
        "As can be seen the coefficients are not the same. However the difference between MSE of both methods is very small. Let us try to plot the reg.fit line and gradient descent line on the same plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3E1OOkaudEy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(df.area,df.price,color='r', marker='+')\n",
        "plt.xlabel('Area ($m^2$)',fontsize=20)\n",
        "plt.ylabel('Prices ($)',fontsize=20)\n",
        "plt.plot(df.area,y_pred_reg,color='b',label='reg.fit') ## best fit line using reg.predict\n",
        "plt.plot(df.area,y_pred_gd,color='g',linestyle='--',linewidth=3,label='Gradient Descent') ## best fit line using gradient descent\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8rvtRECsIlv",
        "colab_type": "text"
      },
      "source": [
        "As can be seen, the reg.fit and the gradient descent lines are exactly the same.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lx8B1I8uwnZa",
        "colab_type": "text"
      },
      "source": [
        "**Exercise**\n",
        "\n",
        "Modify the gradient descent to be used for multiple linear regression with three independent variables. Then use it to estimate the houses' prices given the area, number of bedrooms, and age discussed in the multiple linear regression section."
      ]
    }
  ]
}